providers:
  openai:
    api_key_env: "OPENAI_API_KEY"
    base_url: "https://api.openai.com/v1"
    models:
      - "gpt-4"
      - "gpt-3.5-turbo"
    default_model: "gpt-4"
    
  anthropic:
    api_key_env: "ANTHROPIC_API_KEY"
    base_url: "https://api.anthropic.com"
    models:
      - "claude-3-opus-20240229"
      - "claude-3-sonnet-20240229"
    default_model: "claude-3-sonnet-20240229"
    
  local:
    base_url: "http://localhost:11434"
    models:
      - "llama2"
      - "mistral"
      - "codellama"
    default_model: "llama2"

default_provider: "openai"
fallback_providers: ["anthropic", "local"]

# Rate limiting configuration
rate_limits:
  openai:
    requests_per_minute: 60
    tokens_per_minute: 90000
  anthropic:
    requests_per_minute: 50
    tokens_per_minute: 100000
  local:
    requests_per_minute: 100
    tokens_per_minute: 200000

# Retry configuration
retry_config:
  max_attempts: 3
  base_delay: 2.0
  max_delay: 60.0
  exponential_base: 2