# Covibe Agent Personality System - Environment Configuration
# Copy this file to .env and configure for your environment

# =============================================================================
# Core Application Settings
# =============================================================================
ENVIRONMENT=development
LOG_LEVEL=INFO
DATABASE_URL=sqlite:///app/data/covibe.db

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_ORG_ID=org-your-organization-id  # Optional

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_BASE_URL=https://api.anthropic.com

# Local LLM Configuration (Ollama, LocalAI, etc.)
LOCAL_LLM_BASE_URL=http://localhost:11434
LOCAL_LLM_API_KEY=your-local-api-key  # If required

# =============================================================================
# LLM Research Configuration
# =============================================================================

# Enable/disable LLM-enhanced research
LLM_RESEARCH_ENABLED=true

# Default LLM provider (openai, anthropic, local)
DEFAULT_LLM_PROVIDER=openai

# Fallback providers (comma-separated)
FALLBACK_LLM_PROVIDERS=anthropic,local

# Configuration paths
LLM_CONFIG_PATH=/app/config/llm
PROMPT_CONFIG_PATH=/app/config/prompts

# =============================================================================
# Caching Configuration
# =============================================================================

# Enable LLM response caching
ENABLE_LLM_CACHING=true

# Cache TTL in hours
CACHE_TTL_HOURS=24

# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=your-redis-password
REDIS_DB=0

# Cache backend (memory, redis, file)
CACHE_BACKEND=redis

# =============================================================================
# Performance and Rate Limiting
# =============================================================================

# Maximum concurrent LLM requests
MAX_CONCURRENT_LLM_REQUESTS=10

# Request timeout in seconds
LLM_REQUEST_TIMEOUT=30

# Connection timeout in seconds
LLM_CONNECTION_TIMEOUT=10

# =============================================================================
# Cost Management
# =============================================================================

# Daily budget in USD
DAILY_BUDGET_USD=100.0

# Monthly budget in USD
MONTHLY_BUDGET_USD=2000.0

# Budget warning threshold (0.0-1.0)
BUDGET_WARN_THRESHOLD=0.8

# Stop requests when budget exceeded
STOP_ON_BUDGET_EXCEEDED=true

# =============================================================================
# Security Configuration
# =============================================================================

# Enable input sanitization
ENABLE_INPUT_SANITIZATION=true

# Enable output validation
ENABLE_OUTPUT_VALIDATION=true

# Maximum description length
MAX_DESCRIPTION_LENGTH=2000

# Enable prompt injection detection
ENABLE_PROMPT_INJECTION_DETECTION=true

# =============================================================================
# Logging and Monitoring
# =============================================================================

# Log LLM requests (be careful with sensitive data)
LOG_LLM_REQUESTS=false

# Log LLM responses (be careful with sensitive data)
LOG_LLM_RESPONSES=false

# Enable debug mode
ENABLE_DEBUG_MODE=false

# Log directory
LOG_DIR=/app/logs

# Enable metrics collection
ENABLE_METRICS=true

# Metrics port
METRICS_PORT=9090

# =============================================================================
# Development Settings
# =============================================================================

# Enable hot reloading (development only)
ENABLE_HOT_RELOAD=false

# Enable CORS (development only)
ENABLE_CORS=false

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# =============================================================================
# Production Settings
# =============================================================================

# Secret key for JWT tokens
SECRET_KEY=your-secret-key-here

# API key for authentication
API_KEY=your-api-key-here

# Enable HTTPS redirect
FORCE_HTTPS=false

# Trusted hosts (comma-separated)
TRUSTED_HOSTS=localhost,127.0.0.1,api.covibe.dev

# =============================================================================
# Monitoring and Alerting
# =============================================================================

# Prometheus configuration
PROMETHEUS_ENABLED=false
PROMETHEUS_PORT=9091

# Grafana configuration
GRAFANA_PASSWORD=admin
GRAFANA_ENABLED=false

# Alert webhook URL
ALERT_WEBHOOK_URL=https://hooks.slack.com/your-webhook-url

# Email alerts
ALERT_EMAIL_ENABLED=false
ALERT_EMAIL_FROM=alerts@covibe.dev
ALERT_EMAIL_TO=admin@covibe.dev
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-email-password

# =============================================================================
# Database Configuration (Advanced)
# =============================================================================

# PostgreSQL (alternative to SQLite)
# DATABASE_URL=postgresql://user:password@localhost:5432/covibe

# Database connection pool settings
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_TIMEOUT=30

# =============================================================================
# External Service Integration
# =============================================================================

# GitHub integration (for IDE detection)
GITHUB_TOKEN=ghp_your-github-token

# IDE detection settings
IDE_DETECTION_ENABLED=true
IDE_CONFIG_AUTO_WRITE=true

# =============================================================================
# Advanced LLM Settings
# =============================================================================

# Model-specific configurations
OPENAI_DEFAULT_MODEL=gpt-4
ANTHROPIC_DEFAULT_MODEL=claude-3-sonnet-20240229
LOCAL_DEFAULT_MODEL=llama2:7b

# Temperature settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1500

# Retry settings
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=1.0
LLM_EXPONENTIAL_BACKOFF=true

# =============================================================================
# Feature Flags
# =============================================================================

# Enable experimental features
ENABLE_EXPERIMENTAL_FEATURES=false

# Enable A/B testing
ENABLE_AB_TESTING=false

# Enable usage analytics
ENABLE_ANALYTICS=false

# =============================================================================
# Backup and Recovery
# =============================================================================

# Backup configuration
BACKUP_ENABLED=false
BACKUP_INTERVAL_HOURS=24
BACKUP_RETENTION_DAYS=30
BACKUP_S3_BUCKET=covibe-backups
BACKUP_S3_REGION=us-east-1

# AWS credentials for backups
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key

# =============================================================================
# Container-Specific Settings
# =============================================================================

# Docker-specific environment variables
DOCKER_BUILDKIT=1
COMPOSE_DOCKER_CLI_BUILD=1

# User and group IDs for container permissions
USER_ID=1000
GROUP_ID=1000

# Container resource limits
MEMORY_LIMIT=2g
CPU_LIMIT=1.0